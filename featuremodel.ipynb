{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem Statement**\n",
    "\n",
    "Develop a predictive model to classify deliveries as 'on-time' or 'late' based on historical shipping data. The goal is to maximize precision for on-time deliveries while improving recall for late deliveries to ensure better accuracy in predicting delayed shipments. The model should help logistics and supply chain teams optimize operations, reduce delays, and improve customer satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb \n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_recall_curve,recall_score\n",
    "from sklearn.utils import resample \n",
    "import warnings \n",
    "import joblib \n",
    "from datetime import datetime \n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('preprocessed_data2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for detecting and handling outlier if normally distributed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliersnormal(df,column,n_std=3):\n",
    "    mean=df[column].mean()\n",
    "    std=df[column].std()\n",
    "    z_scores=np.abs((df[column]-mean)/std)\n",
    "    return z_scores>n_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliersnormal(df,column,strategy='clip',n_std=3):\n",
    "    if strategy=='clip':\n",
    "        mean=df[column].mean()\n",
    "        std=df[column].std()\n",
    "        z_scores=np.abs((df[column]-mean)/std)\n",
    "        df[column]=df[column].clip(lower=mean-n_std*std,upper=mean+std*n_std)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for detecting and handling outlier if skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert timestamps to datetime \n",
    "date_columns = ['order_purchase_timestamp', 'order_approved_at', \n",
    "                'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
    "                'order_estimated_delivery_date', 'shipping_limit_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in date_columns:\n",
    "    df[col]=pd.to_datetime(df[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking missing values...\n",
      "order_approved_at                    15\n",
      "order_delivered_carrier_date       1235\n",
      "order_delivered_customer_date      2471\n",
      "review_comment_title             103437\n",
      "review_comment_message            67650\n",
      "product_category_name              1695\n",
      "product_name_length                1695\n",
      "product_description_length         1695\n",
      "product_photos_qty                 1695\n",
      "product_weight_g                     20\n",
      "product_length_cm                    20\n",
      "product_height_cm                    20\n",
      "product_width_cm                     20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking missing values...\")\n",
    "missing_values=df.isnull().sum()\n",
    "print(missing_values[missing_values>0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling missing values...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['review_score', 'payment_sequential', 'payment_installments',\n",
       "       'payment_value', 'customer_zip_code_prefix', 'order_item_id', 'price',\n",
       "       'freight_value', 'product_name_length', 'product_description_length',\n",
       "       'product_photos_qty', 'product_weight_g', 'product_length_cm',\n",
       "       'product_height_cm', 'product_width_cm', 'seller_zip_code_prefix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nHandling missing values...\")\n",
    "numeric_columns=df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_columns:\n",
    "    df[col]=df[col].fillna(df[col].median())\n",
    "    \n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price                7.652230\n",
      "freight_value        5.552235\n",
      "product_weight_g     3.582456\n",
      "product_length_cm    1.745511\n",
      "product_height_cm    2.240139\n",
      "product_width_cm     1.705419\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import skew \n",
    "numeric_cols = ['price', 'freight_value', 'product_weight_g', \n",
    "                'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
    "#this is the only numeric_column we needed \n",
    "# Calculate skewness for each numeric column\n",
    "skewness_values = df[numeric_cols].apply(skew, nan_policy='omit')\n",
    "\n",
    "# Display results\n",
    "print(skewness_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `order_purchase_timestamp` is crucial in predicting whether a delivery will be on time because it provides temporal context about the order. Here’s why it matters:\n",
    "\n",
    "1. **Seasonality & Peak Periods**\n",
    "    - Certain months, such as December and January, might have higher delays due to holidays and increased order volume.\n",
    "    - Weekends might affect delivery times since logistics operations can be slower.\n",
    "    - **Features Derived**: `is_holiday`, `is_weekend`, `purchase_month`, `purchase_quarter`\n",
    "\n",
    "2. **Time of Order Placement (Operational Hours Impact)**\n",
    "    - Orders placed late at night might have processing delays.\n",
    "    - Orders during peak hours (e.g., 9 AM - 5 PM) might be processed faster.\n",
    "    - **Features Derived**: `purchase_hour`, `is_peak_hour`, `is_morning`, `is_afternoon`, `is_evening`\n",
    "\n",
    "3. **Day of the Week Effects**\n",
    "    - If an order is placed on Friday evening, it may not be processed until Monday.\n",
    "    - Different days might have different shipping patterns.\n",
    "    - **Feature Derived**: `purchase_weekday`\n",
    "\n",
    "4. **Lead Time Calculation**\n",
    "    - Helps compute time elapsed between order placement and shipping, which is a critical feature.\n",
    "    - Example: `shipping_delay = order_delivered_customer_date - order_purchase_timestamp`\n",
    "    - A shorter processing time generally increases the likelihood of on-time delivery.\n",
    "\n",
    "5. **Predicting Delays Based on Past Data**\n",
    "    - If historical data shows that orders placed in certain time windows tend to be delayed, the model can learn these patterns and predict potential late deliveries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['purchase_year'] = df['order_purchase_timestamp'].dt.year\n",
    "df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "df['purchase_day'] = df['order_purchase_timestamp'].dt.day\n",
    "df['purchase_weekday'] = df['order_purchase_timestamp'].dt.weekday\n",
    "df['purchase_hour'] = df['order_purchase_timestamp'].dt.hour\n",
    "df['purchase_quarter'] = df['order_purchase_timestamp'].dt.quarter\n",
    "df['is_weekend'] = df['purchase_weekday'].isin([5, 6]).astype(int)\n",
    "df['is_holiday'] = df['purchase_month'].isin([12, 1]).astype(int)\n",
    "df['is_peak_hour'] = df['purchase_hour'].isin([9, 10, 11, 12, 13, 14, 15, 16, 17]).astype(int)\n",
    "df['is_morning'] = df['purchase_hour'].isin([6, 7, 8, 9, 10, 11]).astype(int)\n",
    "df['is_afternoon'] = df['purchase_hour'].isin([12, 13, 14, 15, 16, 17]).astype(int)\n",
    "df['is_evening'] = df['purchase_hour'].isin([18, 19, 20, 21, 22, 23]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Volume \n",
    "This calculates the volume of the product by multiplying its length, height, and width.\n",
    "\n",
    "The volume is a key factor in logistics because larger products may require more space in delivery vehicles.\n",
    "\n",
    "#### Price per unit volume \n",
    "Calculates how expensive the product is per unit volume .\n",
    "\n",
    "#### Price per unit weight \n",
    "Determines how expensive the product is per unit weight.\n",
    "\n",
    "Helps in analyzing how weight impacts delivery cost (e.g., heavier items might require special handling).\n",
    "\n",
    "#### Product Density \n",
    "\n",
    "Calculates the density of the product (weight per volume unit).\n",
    "Helps determine how compact or bulky a product is.\n",
    "Bulky but lightweight items may take up more space, affecting shipping cost and delivery time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Product features(no data leakage )\n",
    "df['product_volume']=df['product_length_cm']*df['product_height_cm']*df['product_width_cm']\n",
    "df['product_volume']=df['product_volume'].replace(0,1)\n",
    "df['price_per_volume']=(df['price']/df['product_volume']).replace([np.inf,-np.inf],0)\n",
    "df['price_per_weight']=(df['price']/df['product_weight_g']).replace([np.inf,-np.inf],0)\n",
    "df['product_density']=(df['product_weight_g']/df['product_volume']).replace([np.inf,-np.inf],0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Example\n",
    "\n",
    "A small but heavy item (e.g., a dumbbell) may be easy to transport, while a large but lightweight item (e.g., a pillow) may take up more space in a vehicle, leading to inefficient deliveries.\n",
    "\n",
    "By incorporating density, volume, and price per unit weight, the model can predict which orders may face delays due to logistics constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_large_item']=(df['product_volume']>df['product_volume'].quantile(0.75)).astype(int)\n",
    "df['is_heavy_item']=(df['product_weight_g']>df['product_weight_g'].quantile(0.75)).astype(int)\n",
    "df['is_expensive']=(df['price']>df['price'].quantile(0.75)).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processing_time'] = (df['order_approved_at'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # in hours\n",
    "df['estimated_delivery_time'] = (df['order_estimated_delivery_date'] - df['order_purchase_timestamp']).dt.total_seconds() / 3600  # in hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Time as a Delay Indicator\n",
    "\n",
    "- **Internal Order Processing Delays**: A longer processing time may push the actual delivery date beyond the estimated date. This helps in analyzing if delays originate from internal order processing.\n",
    "\n",
    "### Estimated Delivery Time vs. Actual Delivery Time\n",
    "\n",
    "- **Aggressive Delivery Promises**: A short estimated delivery time might indicate aggressive delivery promises, leading to frequent delays.\n",
    "- **Buffer Room**: A long estimated time may give buffer room, reducing delay risks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance and logistics features\n",
    "\n",
    "Products with high shipping_cost_ratio → Might be delayed due to expensive shipping options.\n",
    "\n",
    "Products with high weight_to_price_ratio → Might be shipped in bulk, causing longer processing times.\n",
    "\n",
    "Products with high volume_to_weight_ratio → Might need specialized packaging or storage, affecting delivery speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shipping_cost_ratio'] = (df['freight_value'] / df['price']).replace([np.inf, -np.inf], 0)\n",
    "df['weight_to_price_ratio'] = (df['product_weight_g'] / df['price']).replace([np.inf, -np.inf], 0)\n",
    "df['volume_to_weight_ratio'] = (df['product_volume'] / df['product_weight_g'].replace(0, 1)).replace([np.inf, -np.inf], 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What These Features Represent & Why They Are Useful?\n",
    "\n",
    "1️⃣ **price_weight_interaction (price * weight)**\n",
    "\n",
    "- Captures the combined effect of price and weight.\n",
    "- Expensive and heavy products might require premium shipping options.\n",
    "- Useful for detecting fragile or luxury items that need special handling.\n",
    "\n",
    "2️⃣ **price_volume_interaction (price * volume)**\n",
    "\n",
    "- Measures the combined influence of price and volume.\n",
    "- Bulky and expensive products may need specialized transport (e.g., furniture).\n",
    "- Useful for detecting large, high-value items that may have longer processing times.\n",
    "\n",
    "3️⃣ **weight_volume_interaction (weight * volume)**\n",
    "\n",
    "- Identifies products that are both large and heavy.\n",
    "- Heavy, bulky items are harder to transport and may experience longer delivery times.\n",
    "- Can indicate logistics challenges (e.g., need for forklifts, special transport).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['price_weight_interaction'] = df['price'] * df['product_weight_g']\n",
    "df['price_volume_interaction'] = df['price'] * df['product_volume']\n",
    "df['weight_volume_interaction'] = df['product_weight_g'] * df['product_volume']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_delay'] = (df['order_delivered_customer_date'] - df['order_estimated_delivery_date']).dt.total_seconds() / 3600\n",
    "df['on_time_delivery'] = (df['delivery_delay'] <= 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(178989)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = df.replace([np.inf, -np.inf], 0)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Features for modelling ....\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPreparing Features for modelling ....\")\n",
    "target='on_time_delivery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Price and Cost Features\n",
    "    'price', 'freight_value',\n",
    "    \n",
    "    # Product Physical Characteristics\n",
    "    'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm',\n",
    "    \n",
    "    # Time-based Features\n",
    "    'purchase_month', 'purchase_day', 'purchase_weekday', 'purchase_hour',\n",
    "    'is_weekend', 'is_holiday', 'is_peak_hour', 'is_morning', 'is_afternoon', 'is_evening',\n",
    "    \n",
    "    # Product Categories\n",
    "    'is_large_item', 'is_heavy_item', 'is_expensive',\n",
    "    \n",
    "    # Derived Product Features\n",
    "    'product_volume', 'price_per_volume', 'price_per_weight', 'product_density',\n",
    "    \n",
    "    # Delivery Features\n",
    "    'processing_time', 'estimated_delivery_time',\n",
    "    \n",
    "    # Logistics Features\n",
    "    'shipping_cost_ratio', 'weight_to_price_ratio', 'volume_to_weight_ratio',\n",
    "    \n",
    "    # Interaction Features\n",
    "    'price_weight_interaction', 'price_volume_interaction', 'weight_volume_interaction'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSplitting data...\")\n",
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=0.8, random_state=42)\n",
    "X_train_balanced, y_train_balanced = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test, threshold='median'):\n",
    "    # Use Random Forest for feature selection\n",
    "    selector = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit selector\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Select features\n",
    "    feature_selector = SelectFromModel(selector, threshold=threshold)\n",
    "    feature_selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Transform data\n",
    "    X_train_selected = feature_selector.transform(X_train)\n",
    "    X_test_selected = feature_selector.transform(X_test)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = [features[i] for i in range(len(features)) if feature_selector.get_support()[i]]\n",
    "    \n",
    "    return X_train_selected, X_test_selected, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing feature selection...\n",
      "Selected 18 features out of 31\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerforming feature selection...\")\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "selector.fit(X_train_balanced, y_train_balanced)\n",
    "selected_features = X.columns[selector.get_support()].tolist()\n",
    "X_train_selected = selector.transform(X_train_balanced)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "print(f\"Selected {len(selected_features)} features out of {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'freight_value',\n",
       " 'product_height_cm',\n",
       " 'product_width_cm',\n",
       " 'purchase_month',\n",
       " 'purchase_day',\n",
       " 'product_volume',\n",
       " 'price_per_volume',\n",
       " 'price_per_weight',\n",
       " 'product_density',\n",
       " 'processing_time',\n",
       " 'estimated_delivery_time',\n",
       " 'shipping_cost_ratio',\n",
       " 'weight_to_price_ratio',\n",
       " 'volume_to_weight_ratio',\n",
       " 'price_weight_interaction',\n",
       " 'price_volume_interaction',\n",
       " 'weight_volume_interaction']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        min_child_weight=3,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating models...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining and evaluating models...\")\n",
    "best_model=None\n",
    "best_score=0\n",
    "model_results={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.7739\n",
      "Average Precision: 0.9570\n",
      "Cross-validation Accuracy: 0.7421 (+/- 0.0521)\n",
      "Cross-validation Precision: 0.7636 (+/- 0.0545)\n",
      "Cross-validation Recall: 0.7772 (+/- 0.0706)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.69      0.32       182\n",
      "           1       0.97      0.78      0.86      2136\n",
      "\n",
      "    accuracy                           0.77      2318\n",
      "   macro avg       0.59      0.73      0.59      2318\n",
      "weighted avg       0.91      0.77      0.82      2318\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 125   57]\n",
      " [ 467 1669]]\n",
      "\n",
      "Training XGBoost...\n",
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.8080\n",
      "Average Precision: 0.9623\n",
      "Cross-validation Accuracy: 0.7482 (+/- 0.0528)\n",
      "Cross-validation Precision: 0.7577 (+/- 0.0429)\n",
      "Cross-validation Recall: 0.8035 (+/- 0.0635)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.72      0.37       182\n",
      "           1       0.97      0.82      0.89      2136\n",
      "\n",
      "    accuracy                           0.81      2318\n",
      "   macro avg       0.61      0.77      0.63      2318\n",
      "weighted avg       0.91      0.81      0.85      2318\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 131   51]\n",
      " [ 394 1742]]\n",
      "\n",
      "Training Gradient Boosting...\n",
      "\n",
      "Gradient Boosting Results:\n",
      "Accuracy: 0.8076\n",
      "Average Precision: 0.9627\n",
      "Cross-validation Accuracy: 0.7537 (+/- 0.0455)\n",
      "Cross-validation Precision: 0.7668 (+/- 0.0432)\n",
      "Cross-validation Recall: 0.8002 (+/- 0.0550)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.73      0.37       182\n",
      "           1       0.97      0.81      0.89      2136\n",
      "\n",
      "    accuracy                           0.81      2318\n",
      "   macro avg       0.61      0.77      0.63      2318\n",
      "weighted avg       0.92      0.81      0.85      2318\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 132   50]\n",
      " [ 396 1740]]\n",
      "\n",
      "Best model: XGBoost (Accuracy: 0.8080)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_selected, y_train_balanced)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    avg_precision = average_precision_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    model_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'avg_precision': avg_precision,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    # Perform cross-validation with selected features\n",
    "    cv_scores = cross_val_score(model, X_train_selected, y_train_balanced, cv=5)\n",
    "    cv_precision = cross_val_score(model, X_train_selected, y_train_balanced, cv=5, scoring='precision')\n",
    "    cv_recall = cross_val_score(model, X_train_selected, y_train_balanced, cv=5, scoring='recall')\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Cross-validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(f\"Cross-validation Precision: {cv_precision.mean():.4f} (+/- {cv_precision.std() * 2:.4f})\")\n",
    "    print(f\"Cross-validation Recall: {cv_recall.mean():.4f} (+/- {cv_recall.std() * 2:.4f})\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Update best model\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "        best_predictions = y_pred\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} (Accuracy: {best_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features for delivery performance:\n",
      "                     feature  importance\n",
      "4             purchase_month    0.136778\n",
      "11   estimated_delivery_time    0.107845\n",
      "5               purchase_day    0.065705\n",
      "1              freight_value    0.063598\n",
      "13     weight_to_price_ratio    0.052839\n",
      "3           product_width_cm    0.051832\n",
      "8           price_per_weight    0.048331\n",
      "16  price_volume_interaction    0.046543\n",
      "0                      price    0.044848\n",
      "10           processing_time    0.044138\n"
     ]
    }
   ],
   "source": [
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': selected_features,\n",
    "        'importance': best_model.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 most important features for delivery performance:\")\n",
    "    print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documentation(results, feature_importance, df, models):\n",
    "    \"\"\"Create comprehensive documentation of the model training and evaluation process\"\"\"\n",
    "    doc = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_performance': {},\n",
    "        'feature_importance': feature_importance.to_dict('records'),\n",
    "        'data_statistics': {\n",
    "            'total_samples': len(df),\n",
    "            'class_distribution': df['on_time_delivery'].value_counts().to_dict(),\n",
    "            'missing_values': df.isnull().sum().to_dict()\n",
    "        },\n",
    "        'experimentation_details': {\n",
    "            'preprocessing_steps': [\n",
    "                'Missing value handling using median for numeric columns',\n",
    "                'Outlier detection and handling using z-score method',\n",
    "                'Feature scaling using RobustScaler',\n",
    "                'Class imbalance handling using conservative undersampling',\n",
    "                'Feature selection using Random Forest'\n",
    "            ],\n",
    "            'feature_engineering': [\n",
    "                'Time-based features (month, day, weekday, hour)',\n",
    "                'Product physical characteristics',\n",
    "                'Derived features (volume, density, ratios)',\n",
    "                'Interaction features'\n",
    "            ],\n",
    "            'model_configurations': {\n",
    "                name: str(model.get_params()) for name, model in models.items()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for name, result in results.items():\n",
    "        doc['model_performance'][name] = {\n",
    "            'accuracy': result['accuracy'],\n",
    "            'average_precision': result['avg_precision']\n",
    "        }\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_business_insights(y_test, y_pred, df, feature_importance):\n",
    "    \"\"\"Create business-focused insights and visualizations\"\"\"\n",
    "    # Calculate business metrics\n",
    "    total_deliveries = len(y_test)\n",
    "    on_time_deliveries = sum(y_test == 1)\n",
    "    late_deliveries = sum(y_test == 0)\n",
    "    correctly_predicted_on_time = sum((y_test == 1) & (y_pred == 1))\n",
    "    correctly_predicted_late = sum((y_test == 0) & (y_pred == 0))\n",
    "    \n",
    "    # Calculate cost implications (example values)\n",
    "    avg_delivery_cost = 50  # Example cost per delivery\n",
    "    late_delivery_penalty = 20  # Example penalty for late delivery\n",
    "    customer_satisfaction_impact = 0.8  # Example satisfaction impact for on-time delivery\n",
    "    \n",
    "    # Calculate financial impact\n",
    "    total_cost = total_deliveries * avg_delivery_cost\n",
    "    penalty_cost = late_deliveries * late_delivery_penalty\n",
    "    potential_savings = correctly_predicted_late * late_delivery_penalty\n",
    "    \n",
    "    # Create business insights dictionary\n",
    "    business_insights = {\n",
    "        'delivery_metrics': {\n",
    "            'total_deliveries': total_deliveries,\n",
    "            'on_time_rate': (on_time_deliveries / total_deliveries) * 100,\n",
    "            'late_rate': (late_deliveries / total_deliveries) * 100,\n",
    "            'correctly_predicted_on_time': correctly_predicted_on_time,\n",
    "            'correctly_predicted_late': correctly_predicted_late\n",
    "        },\n",
    "        'financial_impact': {\n",
    "            'total_delivery_cost': total_cost,\n",
    "            'penalty_cost': penalty_cost,\n",
    "            'potential_savings': potential_savings,\n",
    "            'roi_percentage': (potential_savings / total_cost) * 100\n",
    "        },\n",
    "        'customer_satisfaction': {\n",
    "            'predicted_on_time_satisfaction': correctly_predicted_on_time * customer_satisfaction_impact,\n",
    "            'total_potential_satisfaction': on_time_deliveries * customer_satisfaction_impact\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return business_insights\n",
    "\n",
    "def create_client_visualizations(business_insights, feature_importance):\n",
    "    \"\"\"Create client-friendly visualizations\"\"\"\n",
    "    plt.style.use('default')  # Use default style instead of seaborn\n",
    "    \n",
    "    # Set custom style parameters\n",
    "    plt.rcParams['figure.figsize'] = [20, 15]\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.titlesize'] = 14\n",
    "    plt.rcParams['axes.labelsize'] = 12\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    # 1. Delivery Performance Overview\n",
    "    plt.subplot(3, 2, 1)\n",
    "    delivery_metrics = business_insights['delivery_metrics']\n",
    "    labels = ['On-Time', 'Late']\n",
    "    sizes = [delivery_metrics['on_time_rate'], delivery_metrics['late_rate']]\n",
    "    colors = ['#2ecc71', '#e74c3c']\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Delivery Performance Overview', pad=20)\n",
    "    \n",
    "    # 2. Financial Impact\n",
    "    plt.subplot(3, 2, 2)\n",
    "    financial = business_insights['financial_impact']\n",
    "    costs = [financial['total_delivery_cost'], financial['penalty_cost'], financial['potential_savings']]\n",
    "    labels = ['Total Cost', 'Penalty Cost', 'Potential Savings']\n",
    "    bars = plt.bar(labels, costs, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "    plt.title('Financial Impact Analysis', pad=20)\n",
    "    plt.xticks(rotation=45)\n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'${height:,.0f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Feature Importance (Top 5)\n",
    "    plt.subplot(3, 2, 3)\n",
    "    top_features = feature_importance.head(5)\n",
    "    bars = plt.barh(top_features['feature'], top_features['importance'], color='#3498db')\n",
    "    plt.title('Top 5 Factors Affecting Delivery Performance', pad=20)\n",
    "    # Add percentage labels\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                f'{width*100:.1f}%',\n",
    "                ha='left', va='center')\n",
    "    \n",
    "    # 4. Customer Satisfaction Impact\n",
    "    plt.subplot(3, 2, 4)\n",
    "    satisfaction = business_insights['customer_satisfaction']\n",
    "    metrics = ['Predicted\\nOn-Time\\nSatisfaction', 'Total\\nPotential\\nSatisfaction']\n",
    "    values = [satisfaction['predicted_on_time_satisfaction'], satisfaction['total_potential_satisfaction']]\n",
    "    bars = plt.bar(metrics, values, color=['#2ecc71', '#3498db'])\n",
    "    plt.title('Customer Satisfaction Impact', pad=20)\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.0f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # 5. ROI Analysis\n",
    "    plt.subplot(3, 2, 5)\n",
    "    roi = business_insights['financial_impact']['roi_percentage']\n",
    "    plt.pie([roi, 100-roi], labels=['ROI', 'Cost'], colors=['#2ecc71', '#e74c3c'],\n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Return on Investment Analysis', pad=20)\n",
    "    \n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.savefig('business_insights.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def generate_client_report(business_insights, feature_importance):\n",
    "    \"\"\"Generate a client-friendly report\"\"\"\n",
    "    report = {\n",
    "        'executive_summary': {\n",
    "            'model_performance': {\n",
    "                'accuracy': f\"{business_insights['delivery_metrics']['on_time_rate']:.1f}%\",\n",
    "                'prediction_confidence': \"High\",\n",
    "                'roi_potential': f\"{business_insights['financial_impact']['roi_percentage']:.1f}%\"\n",
    "            },\n",
    "            'key_benefits': [\n",
    "                \"Improved delivery reliability\",\n",
    "                \"Reduced operational costs\",\n",
    "                \"Enhanced customer satisfaction\",\n",
    "                \"Better resource allocation\"\n",
    "            ]\n",
    "        },\n",
    "        'business_impact': {\n",
    "            'cost_savings': f\"${business_insights['financial_impact']['potential_savings']:,.2f}\",\n",
    "            'customer_satisfaction': f\"{business_insights['customer_satisfaction']['predicted_on_time_satisfaction']:.0f}\",\n",
    "            'delivery_reliability': f\"{business_insights['delivery_metrics']['on_time_rate']:.1f}%\"\n",
    "        },\n",
    "        'key_factors': {\n",
    "            'top_5_features': feature_importance.head(5)['feature'].tolist(),\n",
    "            'recommendations': [\n",
    "                \"Optimize delivery routes based on temporal patterns\",\n",
    "                \"Focus on high-risk delivery windows\",\n",
    "                \"Implement proactive customer communication\",\n",
    "                \"Allocate resources based on predicted delivery performance\"\n",
    "            ]\n",
    "        },\n",
    "        'implementation_guide': {\n",
    "            'immediate_actions': [\n",
    "                \"Integrate model predictions into delivery planning\",\n",
    "                \"Set up monitoring for key performance indicators\",\n",
    "                \"Train staff on using prediction insights\",\n",
    "                \"Establish feedback loop for continuous improvement\"\n",
    "            ],\n",
    "            'long_term_strategies': [\n",
    "                \"Regular model retraining with new data\",\n",
    "                \"Expansion to additional delivery routes\",\n",
    "                \"Integration with customer communication systems\",\n",
    "                \"Development of automated reporting dashboards\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save report to JSON\n",
    "    with open('client_report.json', 'w') as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model documentation saved to model_documentation.json\n",
      "\n",
      "Generating business insights and client materials...\n",
      "\n",
      "Client materials generated successfully:\n",
      "1. Business insights visualization saved as 'business_insights.png'\n",
      "2. Detailed client report saved as 'client_report.json'\n",
      "\n",
      "Key Business Metrics:\n",
      "- Overall Delivery Performance: 92.1%\n",
      "- Potential Cost Savings: $2,620.00\n",
      "- ROI Potential: 2.3%\n",
      "- Customer Satisfaction Impact: 1394\n",
      "\n",
      "Business Insights:\n",
      "1. Overall delivery performance: 92.14% on-time deliveries\n",
      "2. Key factors affecting delivery performance:\n",
      "   - purchase_month: 13.68% importance\n",
      "   - estimated_delivery_time: 10.78% importance\n",
      "   - purchase_day: 6.57% importance\n",
      "   - freight_value: 6.36% importance\n",
      "   - weight_to_price_ratio: 5.28% importance\n",
      "3. Temporal patterns:\n",
      "   - Weekend delivery performance: 93.80%\n",
      "   - Weekday delivery performance: 91.68%\n",
      "   - Holiday delivery performance: 66.67%\n",
      "4. Product characteristics impact:\n",
      "   - Heavy products (>3kg) on-time rate: 89.75%\n",
      "   - Light products (≤3kg) on-time rate: 92.63%\n",
      "\n",
      "Overfitting Analysis:\n",
      "\n",
      "Random Forest:\n",
      "Training CV Accuracy: 0.7537 (+/- 0.0455)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining CV Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining CV Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_precision\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_precision\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_base.py:158\u001b[0m, in \u001b[0;36mBaseEnsemble.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the index'th estimator in the ensemble.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "doc = create_documentation(model_results, feature_importance, df, models)\n",
    "with open('model_documentation.json', 'w') as f:\n",
    "    json.dump(doc, f, indent=4)\n",
    "print(\"\\nModel documentation saved to model_documentation.json\")\n",
    "\n",
    "# Generate business insights and client materials\n",
    "print(\"\\nGenerating business insights and client materials...\")\n",
    "business_insights = create_business_insights(y_test, best_predictions, df, feature_importance)\n",
    "create_client_visualizations(business_insights, feature_importance)\n",
    "client_report = generate_client_report(business_insights, feature_importance)\n",
    "\n",
    "print(\"\\nClient materials generated successfully:\")\n",
    "print(\"1. Business insights visualization saved as 'business_insights.png'\")\n",
    "print(\"2. Detailed client report saved as 'client_report.json'\")\n",
    "\n",
    "print(\"\\nKey Business Metrics:\")\n",
    "print(f\"- Overall Delivery Performance: {business_insights['delivery_metrics']['on_time_rate']:.1f}%\")\n",
    "print(f\"- Potential Cost Savings: ${business_insights['financial_impact']['potential_savings']:,.2f}\")\n",
    "print(f\"- ROI Potential: {business_insights['financial_impact']['roi_percentage']:.1f}%\")\n",
    "print(f\"- Customer Satisfaction Impact: {business_insights['customer_satisfaction']['predicted_on_time_satisfaction']:.0f}\")\n",
    "\n",
    "# Print business insights\n",
    "print(\"\\nBusiness Insights:\")\n",
    "print(f\"1. Overall delivery performance: {df['on_time_delivery'].mean()*100:.2f}% on-time deliveries\")\n",
    "print(\"2. Key factors affecting delivery performance:\")\n",
    "for feature, importance in feature_importance.head(5).values:\n",
    "    print(f\"   - {feature}: {importance*100:.2f}% importance\")\n",
    "print(\"3. Temporal patterns:\")\n",
    "print(f\"   - Weekend delivery performance: {df[df['is_weekend']==1]['on_time_delivery'].mean()*100:.2f}%\")\n",
    "print(f\"   - Weekday delivery performance: {df[df['is_weekend']==0]['on_time_delivery'].mean()*100:.2f}%\")\n",
    "print(f\"   - Holiday delivery performance: {df[df['is_holiday']==1]['on_time_delivery'].mean()*100:.2f}%\")\n",
    "print(\"4. Product characteristics impact:\")\n",
    "print(f\"   - Heavy products (>3kg) on-time rate: {df[df['product_weight_g']>3000]['on_time_delivery'].mean()*100:.2f}%\")\n",
    "print(f\"   - Light products (≤3kg) on-time rate: {df[df['product_weight_g']<=3000]['on_time_delivery'].mean()*100:.2f}%\")\n",
    "\n",
    "# Overfitting Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
